{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOW4ymXDzfuxj6QzIFtmjxt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Multimodal AGI Architecture Implementation\n","\n","**Copyright Â© 2025 by Ananya Soni. All Rights Reserved.**\n","\n","---\n","\n","### **Terms of Use: For Personal Learning Only**\n","\n","This project is made public so others may **run the code, study, and learn** from its implementation, including the unique:\n","* Multimodal AI\n","* Computer Vision & NLP\n","* Generative AI & Deep Learning\n","* Spiking Neural Networks (SNN)\n","\n","**STRICTLY FORBIDDEN:**\n","\n","1.  **COMMERCIAL USE:** You may **not** use this project for any profit-making or commercial purpose whatsoever.\n","2.  **AUTHORSHIP CLAIM:** The **original authorship is retained by Ananya Soni.** You may **not** claim to be the creator of this project or its unique components (Replicated Synapse, Frontal Lobe)."],"metadata":{"id":"m4GLmWo6WoA4"}},{"cell_type":"markdown","source":["# ðŸŒŸ Temporal Causal Synthesis Network (TCS-25) - Core Architecture\n","\n","## Introduction: A Novel AGI Paradigm\n","The **Temporal Causal Synthesis Network (TCS-25)** is a hyper-advanced deep learning architecture designed for **Multimodal General Intelligence (MGI)**. It integrates neuro-inspired mechanisms like **Generalized Plasticity (G-Plasticity)**, **Axiomatic Knowledge Systems (AKS)**, and a **Conscious Global Workspace (CGW)** to achieve human-like, system-2 reasoning and dynamic goal pursuit across 21 parallel data streams.\n","\n","This notebook implements the full, 10-cell architecture definition using TensorFlow/Keras.\n","\n","---\n","\n","## Cell 1: Essential Imports and Hyper-Advanced Constants\n","\n","This cell defines all necessary library dependencies and establishes the **global hyperparameters**. The scale of these constants (e.g., $\\text{HYPER\\_LATENT\\_DIM}=4096$, $\\text{NUM\\_PFC\\_CONTEXTS}=64$) reflects a commitment to advanced, high-capacity models for complex cognitive tasks. Defining them first ensures modularity and ease of future scaling."],"metadata":{"id":"rXXcV1CDdAwM"}},{"cell_type":"code","source":["# Cell 1 â€” imports and constants\n","import tensorflow as tf\n","from tensorflow.keras.layers import Layer, Input, Dense, Conv2D, Flatten, Embedding, LSTM, GRU, Bidirectional, TimeDistributed, GlobalMaxPooling1D, Concatenate, Multiply, BatchNormalization, Dot, Reshape, Dropout, Attention\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import traceback\n","import random\n","import itertools\n","\n","# --- Global Constants for TCS-25 Architecture (Hyper-Advanced) ---\n","IMAGE_SHAPE = (128, 128, 3)\n","DATA_INPUT_SIZE = 512\n","TS_STEPS = 10\n","TS_DIM = 8\n","SEQ_LEN = 50\n","SEQ_DIM = 64\n","GRAPH_DIM = 32\n","VOCAB_SIZE = 10000\n","NUM_CLASSES = 10\n","FRONTAL_LOBE_UNITS = 2048 # Doubled capacity\n","HYPER_LATENT_DIM = 4096 # Doubled Hyper-Dimensional Latent Space\n","NUM_PFC_CONTEXTS = 64 # Doubled for deeper executive control\n","RELATIONAL_EMB_DIM = 512 # Doubled for richer relational reasoning\n","CAUSAL_STATE_DIM = 256 # Doubled for richer Causal Inference Module\n","AXIOMATIC_DIM = 128 # NEW: Dimension for Axiomatic Knowledge Embeddings\n","MLC_OUTPUT_DIM = 5 # Output dimension for Meta-Learning Control\n","LOSS_WEIGHT_SSTC = 0.95 # Stronger emphasis on Self-Supervised Temporal Contrastive\n","TRAINING_BATCH_SIZE = 32 # Smaller batch for stability with larger model"],"metadata":{"id":"9gHe3NdEdPZJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 2: Generalized Plasticity (G-Plasticity) and Hebbian Mixin\n","\n","This component introduces **G-Plasticity**, a mechanism inspired by meta-plasticity in the human brain. It extends standard backpropagation by adding a **Hebb-based update term** ($\\Delta W_P \\propto \\text{pre} \\cdot \\text{post}$), which is dynamically gated by two internal cognitive signals: **Surprisal** (prediction error) and **Causal Error** (disagreement with causal inference).\n","\n","The `GPlasticityMixin` manages these signals and the dynamic plasticity rate output by the $\\text{Meta-Learning Control (MLC)}$ head, allowing the network to **learn *how* and *when* to learn** based on context and surprise."],"metadata":{"id":"NLh4Lq3PdsWj"}},{"cell_type":"code","source":["# Cell 2 â€” G-Plasticity mixin and plastic layers\n","class GPlasticityMixin:\n","    \"\"\"TCS-25's base mixin for Generalized Plasticity (G-Plasticity), now with dynamic rate.\"\"\"\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        # Neuromodulatory signals (tf tensors)\n","        self.surprisal_signal = tf.constant([[0.0]], dtype=tf.float32)\n","        self.causal_signal = tf.constant([[0.0]], dtype=tf.float32)\n","        self.dynamic_plasticity_strength = tf.constant([[0.0001]], dtype=tf.float32)\n","        self.w_old = None\n","        self.x_input = None\n","        self.y_output = None\n","\n","    def calculate_plasticity_change(self):\n","        if self.w_old is None or self.x_input is None or self.y_output is None:\n","            return tf.constant(0.0, dtype=tf.float32), tf.constant(0.0, dtype=tf.float32)\n","\n","        hebbian_term = tf.matmul(tf.transpose(self.x_input), self.y_output) / tf.cast(tf.shape(self.x_input)[0], tf.float32)\n","        modulation_scalar = 0.6 * tf.cast(self.surprisal_signal[0, 0], tf.float32) + 0.4 * tf.cast(self.causal_signal[0, 0], tf.float32)\n","        delta_p = tf.cast(self.dynamic_plasticity_strength[0, 0], tf.float32) * modulation_scalar * hebbian_term\n","        return delta_p, tf.norm(delta_p)\n","\n","    def track_activations(self, x_input, y_output):\n","        self.x_input = tf.stop_gradient(x_input)\n","        self.y_output = tf.stop_gradient(y_output)\n","\n","class GPlasticDense(GPlasticityMixin, Dense):\n","    \"\"\"G-Plastic Dense\"\"\"\n","    def __init__(self, units, activation='tanh', **kwargs):\n","        super().__init__(units=units, activation=activation, **kwargs)\n","\n","    def call(self, inputs):\n","        self.w_old = self.weights[0] if self.weights else None\n","        output = super().call(inputs)\n","        self.track_activations(inputs, output)\n","        return output\n","\n","class GPlasticConv2D(GPlasticityMixin, Conv2D):\n","    \"\"\"G-Plastic Conv2D\"\"\"\n","    def __init__(self, filters, kernel_size, activation='relu', **kwargs):\n","        super().__init__(filters=filters, kernel_size=kernel_size, activation=activation, **kwargs)\n","\n","    def call(self, inputs):\n","        self.w_old = self.weights[0] if self.weights else None\n","        output = super().call(inputs)\n","        flat_out = Flatten()(output)\n","        self.track_activations(inputs, flat_out)\n","        return output\n","\n","class GPlasticGRU(GPlasticityMixin, Layer):\n","    \"\"\"G-Plastic GRU wrapper\"\"\"\n","    def __init__(self, units, **kwargs):\n","        super().__init__(**kwargs)\n","        self.gru_cell = GRU(units, return_sequences=False, return_state=True)\n","        self.proj_input = GPlasticDense(units, activation='tanh', name='gplastic_gru_input_proj')\n","\n","    def call(self, inputs, initial_state=None):\n","        projected_input = self.proj_input(inputs)\n","        output, state = self.gru_cell(projected_input, initial_state=initial_state)\n","        # store weight snapshot for potential plasticity usage\n","        self.w_old = self.gru_cell.weights[0] if self.gru_cell.weights else None\n","        return output, state"],"metadata":{"id":"YBQXiFwod_jz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 3: Axiomatic Knowledge System (AKS) and Episodic Relational Memory (ERM)\n","\n","This cell defines two critical memory and knowledge components:\n","\n","1.  **Axiomatic Knowledge Layer (AKL):** This layer provides a **stable, non-plastic foundation** of fundamental truths (e.g., physical laws, mathematical principles). It is integrated via a fixed embedding matrix, preventing the model from \"forgetting\" core knowledge during training and providing a base for high-level reasoning.\n","2.  **Episodic Relational Memory (ERM):** A simplified, graph-based buffer that stores past state, context, and causal vectors. The ERM allows the network to **retrieve past experiences** relevant to the current query, providing crucial contextual cues for the $\\text{Frontal Lobe}$ and $\\text{Causal Inference Module}$."],"metadata":{"id":"OT25y2AAePg7"}},{"cell_type":"code","source":["# Cell 3 â€” AKL and EpisodicRelationalMemory\n","class AxiomaticKnowledgeLayer(Layer):\n","    \"\"\"Provides an axiomatic, structured knowledge vector for context.\"\"\"\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.axiom_embeddings = self.add_weight(\n","            name=\"axiom_emb_matrix\",\n","            shape=(NUM_PFC_CONTEXTS, AXIOMATIC_DIM),\n","            initializer='glorot_uniform',\n","            trainable=True\n","        )\n","        self.context_to_axiom_proj = GPlasticDense(AXIOMATIC_DIM, activation='tanh', name='axiom_proj_plastic')\n","\n","    def call(self, context_mask):\n","        expanded_mask = tf.expand_dims(context_mask, axis=-1)\n","        weighted_axioms = expanded_mask * self.axiom_embeddings\n","        return tf.reduce_sum(weighted_axioms, axis=1)\n","\n","class EpisodicRelationalMemory:\n","    \"\"\"Graph-based memory for episodes.\"\"\"\n","    def __init__(self):\n","        self.buffer = []\n","        self.max_size = 10000\n","        self.graph_nodes = {}\n","        self.graph_edges = {}\n","\n","    def store(self, state_vector, context_mask, causal_vector):\n","        node_id = len(self.buffer)\n","        episode = {\n","            'state': state_vector[0].numpy(),\n","            'context': context_mask[0].numpy(),\n","            'causal': causal_vector[0].numpy(),\n","            'id': node_id\n","        }\n","        self.buffer.append(episode)\n","        self.graph_nodes[node_id] = episode\n","\n","        if node_id > 0:\n","            past_node_id = random.randint(0, node_id - 1)\n","            relation_vec = np.random.rand(CAUSAL_STATE_DIM).astype(np.float32)\n","            self.graph_edges.setdefault(past_node_id, []).append((node_id, relation_vec))\n","\n","        if len(self.buffer) > self.max_size:\n","            old_node = self.buffer.pop(0)\n","            del self.graph_nodes[old_node['id']]\n","            if old_node['id'] in self.graph_edges:\n","                del self.graph_edges[old_node['id']]\n","\n","    def retrieve_context(self, query_vector):\n","        if not self.graph_nodes:\n","            return tf.zeros((1, FRONTAL_LOBE_UNITS + CAUSAL_STATE_DIM), dtype=tf.float32)\n","        query = np.asarray(query_vector[0])\n","        query_len = query.shape[-1]\n","        scores = []\n","        nodes = list(self.graph_nodes.values())\n","        for node in nodes:\n","            node_state_slice = node['state'][:query_len]\n","            denom = (np.linalg.norm(query) * np.linalg.norm(node_state_slice) + 1e-8)\n","            score = float(np.dot(query, node_state_slice) / denom)\n","            scores.append(score)\n","        weights = np.exp(scores) / np.sum(np.exp(scores))\n","        retrieved_state = np.zeros(FRONTAL_LOBE_UNITS, dtype=np.float32)\n","        retrieved_causal = np.zeros(CAUSAL_STATE_DIM, dtype=np.float32)\n","        for i, node in enumerate(nodes):\n","            retrieved_state += weights[i] * node['state'][:FRONTAL_LOBE_UNITS]\n","            retrieved_causal += weights[i] * node['causal']\n","        retrieved_state = tf.constant(retrieved_state, dtype=tf.float32)[tf.newaxis, :]\n","        retrieved_causal = tf.constant(retrieved_causal, dtype=tf.float32)[tf.newaxis, :]\n","        return Concatenate()([retrieved_state, retrieved_causal])"],"metadata":{"id":"fUjklfYReYLz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 4: Relational Self-Attention (RSA) and Hierarchical Temporal State Processor (HTSP)\n","\n","This section implements two advanced feature-processing units:\n","\n","1.  **Relational Self-Attention (RSA):** A novel attention mechanism that dynamically scales the importance of each of the **21 feature streams** based on their learned **relational context**. This ensures that the network prioritizes relevant modalities (e.g., visual features are down-weighted when only a structural graph input is relevant).\n","2.  **HTSP Unit (Hierarchical Temporal State Processor):** A conceptual unit (simplified here) that would manage **fast (GRU)** and **slow (LSTM)** time scales. This structure is essential for distinguishing between immediate, short-term changes and long-term, slow-evolving causal relationships."],"metadata":{"id":"QfK0eHBqe5lY"}},{"cell_type":"code","source":["# Cell 4 â€” Relational Self-Attention and HTSP\n","class RelationalSelfAttention(Layer):\n","    \"\"\"Dynamically scales features based on global context.\"\"\"\n","    def __init__(self, num_features, feature_dim, **kwargs):\n","        super().__init__(**kwargs)\n","        self.num_features = num_features\n","        self.feature_dim = feature_dim\n","        self.relational_embeddings = self.add_weight(\n","            name=\"relational_emb_matrix\",\n","            shape=(num_features, num_features, RELATIONAL_EMB_DIM),\n","            initializer='glorot_uniform',\n","            trainable=True\n","        )\n","        self.query_gen = GPlasticDense(feature_dim, activation='relu', name='rsa_query_plastic')\n","        self.key_gen = GPlasticDense(feature_dim, activation='relu', name='rsa_key_plastic')\n","        self.rel_context_proj_gate = GPlasticDense(self.num_features * self.num_features, activation='tanh', name='rel_context_proj_gate')\n","        self.attention_weights_generator = GPlasticDense(num_features, activation='softmax', name='rsa_weights_plastic')\n","\n","    def call(self, projected_feature_list):\n","        global_context_fused = Concatenate()(projected_feature_list)\n","        queries = tf.stack([self.query_gen(f) for f in projected_feature_list], axis=1)\n","        keys = tf.stack([self.key_gen(f) for f in projected_feature_list], axis=1)\n","        attention_scores = Dot(axes=-1)([queries, keys])\n","        relational_context_proj = self.rel_context_proj_gate(global_context_fused)\n","        combined_context = Concatenate()([global_context_fused, relational_context_proj])\n","        attention_weights = self.attention_weights_generator(combined_context)\n","        attended_features = []\n","        for i, feature in enumerate(projected_feature_list):\n","            weight = attention_weights[:, i:i+1]\n","            weighted_feature = Multiply()([feature, weight])\n","            attended_features.append(weighted_feature)\n","        return attended_features, attention_weights, tf.reduce_mean(attention_scores)\n","\n","class HTSP_Unit(Layer):\n","    \"\"\"Manages temporal context across different time scales.\"\"\"\n","    def __init__(self, units, **kwargs):\n","        super().__init__(**kwargs)\n","        self.fast_gru = GRU(units // 2, return_sequences=False, return_state=True)\n","        self.slow_lstm = LSTM(units // 2, return_sequences=False, return_state=True)\n","        self.dense_gate = GPlasticDense(units, activation='sigmoid', name='htsp_gate_plastic')\n","    def call(self, inputs, fast_state, slow_state):\n","        fast_output, fast_state = self.fast_gru(inputs, initial_state=fast_state)\n","        slow_output, slow_state_h, slow_state_c = self.slow_lstm(inputs, initial_state=slow_state)\n","        slow_state = [slow_state_h, slow_state_c]\n","        fused = Concatenate()([fast_output, slow_output])\n","        gate = self.dense_gate(fused)\n","        output = Multiply()([fused, gate])\n","        return output, fast_state, slow_state"],"metadata":{"id":"5Id8FMwte_pR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 5: The Cognitive Control Core (CGW, MLC, CIM, BG)\n","\n","This cell defines the primary executive and regulatory modules inspired by cognitive neuroscience:\n","\n","* **Conscious Global Workspace (CGW):** The central hub where all high-level vectors ($\\text{Plastic GRU output, Axiomatic Knowledge, HLS Decoded, MCC Confidence, etc.}$) are fused and gated by a learnable attention mechanism. This output represents the network's **moment-to-moment \"conscious\" state.**\n","* **Basal Ganglia (BG) Selector:** A soft-max gating layer that selects the most appropriate **Prefrontal Cortex (PFC) Context** ($\\text{NUM\\_PFC\\_CONTEXTS}=64$) based on the current $\\text{CGW}$ state and the $\\text{Task Vector}$.\n","* **Causal Inference Module (CIM):** A dense gating unit that processes the $\\text{PFC}$ output and $\\text{ERM}$'s causal context to predict the **next causal state** of the environment.\n","* **Meta-Learning Control (MLC):** Predicts dynamic control parameters, most notably the **MLC Plasticity Rate**, which is fed back to the $\\text{G-Plasticity}$ layers."],"metadata":{"id":"pZcNguWJfMhI"}},{"cell_type":"code","source":["# Cell 5 â€” CGW (Conscious Global Workspace) and executive modules\n","class CGWAttentionLayer(Layer):\n","    \"\"\"Conscious Global Workspace (CGW) Layer (TCS-25).\"\"\"\n","    def build(self, input_shape):\n","        # compute fusion dim\n","        fusion_dim = (input_shape[0][-1] + 1 + 1 + 1 + input_shape[4][-1] + input_shape[5][-1])\n","        self.kernel = self.add_weight(name=\"kernel_fusion\", shape=(fusion_dim, input_shape[0][-1]), initializer='glorot_uniform', trainable=True)\n","        self.gating_dense = GPlasticDense(1, activation='sigmoid', name='cgw_gating_plastic')\n","        super().build(input_shape)\n","    def call(self, plastic_gru_output, scaled_symbolic_bias, scaled_vigilance, mcc_confidence, hls_vector, axiomatic_vector):\n","        fused = Concatenate()([plastic_gru_output, scaled_symbolic_bias, scaled_vigilance, mcc_confidence, hls_vector, axiomatic_vector])\n","        gated_fused = Multiply()([fused, self.gating_dense(fused)])\n","        output = tf.matmul(gated_fused, self.kernel)\n","        return output\n","\n","class MetaLearningControl(Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.dense_pred = GPlasticDense(MLC_OUTPUT_DIM, activation='sigmoid', name='mlc_output_gplastic')\n","        self.dropout = Dropout(0.2)\n","    def call(self, pfc_gated_output):\n","        x = self.dropout(pfc_gated_output)\n","        return self.dense_pred(x)\n","\n","class BasalGangliaSelectionLayer(Layer):\n","    def __init__(self, num_contexts, **kwargs):\n","        super().__init__(**kwargs)\n","        self.context_gate = GPlasticDense(num_contexts, activation='softmax', name='bg_context_gate_gplastic')\n","    def call(self, cgw_output, task_vector_input):\n","        fusion = Concatenate()([cgw_output, task_vector_input])\n","        return self.context_gate(fusion)\n","\n","class MultiContextExecutiveGating(Layer):\n","    def __init__(self, units, num_contexts, **kwargs):\n","        super().__init__(**kwargs)\n","        self.context_networks = [GPlasticDense(units, activation='tanh', name=f'pfc_context_gplastic_{i}') for i in range(num_contexts)]\n","    def call(self, cgw_output, context_mask):\n","        context_outputs = tf.stack([net(cgw_output) for net in self.context_networks], axis=1)\n","        weighted_mask = tf.expand_dims(context_mask, axis=-1)\n","        gated_output = Multiply()([context_outputs, weighted_mask])\n","        return tf.reduce_sum(gated_output, axis=1)\n","\n","class CausalInferenceModule(Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.dense = GPlasticDense(CAUSAL_STATE_DIM, activation='sigmoid', name='cim_causal_output_gplastic')\n","        self.gating = GPlasticDense(CAUSAL_STATE_DIM, activation='tanh', name='cim_gating_gplastic')\n","    def call(self, pfc_gated_output, retrieved_causal_context):\n","        fused = Concatenate()([pfc_gated_output, retrieved_causal_context])\n","        return Multiply()([self.dense(fused), self.gating(fused)])"],"metadata":{"id":"FrSbssobfSMG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 6: Hyper-Latent State (HLS) Processor and Core Model Builder Setup\n","\n","This section defines the $\\text{Hyper-Latent State (HLS)}$ system and the input structure for the final model:\n","\n","1.  **HLS Processor/Decoder:** The $\\text{HLS}$ is a massive, high-dimensional vector ($\\text{HYPER\\_LATENT\\_DIM}=4096$) designed to capture a sparse, high-level summary of the network's state. The $\\text{Processor}$ projects the $\\text{PFC}$ output into this space, and the $\\text{Decoder}$ brings it back to a working dimension for the $\\text{CGW}$.\n","2.  **Core Model Builder:** This function defines **all 21 input streams** (Image, Text, Time Series, Graph, etc.) and the 4 control inputs ($\\text{Vigilance, Bias, Task, Retrieval}$) that feed into the massive architecture."],"metadata":{"id":"tvcj4-Dpfx6-"}},{"cell_type":"code","source":["# Cell 6 â€” HLS Processor and start of core model builder\n","class HLS_Processor(Layer):\n","    \"\"\"Projects the PFC output into the massive, sparse HLS.\"\"\"\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.input_proj = GPlasticDense(FRONTAL_LOBE_UNITS * 2, activation='relu', name='hls_input_proj_plastic')\n","        # Minimal fix: instantiate as a plastic dense layer (previous mixin misuse corrected)\n","        self.latent_dense = GPlasticDense(HYPER_LATENT_DIM, activation='relu', name='hls_core_plastic', use_bias=False)\n","    def build(self, input_shape):\n","        self.latent_dense.build(input_shape)\n","        super().build(input_shape)\n","    def call(self, pfc_output):\n","        x = self.input_proj(pfc_output)\n","        hls_output_raw = self.latent_dense(x)\n","        return hls_output_raw\n","\n","class HLS_Decoder(Layer):\n","    def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","        self.decoder = GPlasticDense(FRONTAL_LOBE_UNITS // 2, activation='tanh', name='hls_decoder_plastic')\n","    def call(self, hls_vector):\n","        return self.decoder(hls_vector)\n","\n","def build_tcs_net_core_model(image_shape, data_size, ts_steps, ts_dim, seq_len, seq_dim, graph_dim, num_classes):\n","    # Inputs\n","    s1_image_input = Input(shape=image_shape, name='stream_01_image_input')\n","    s9_small_cnn_input = Input(shape=(32, 32, 1), name='stream_09_small_cnn_input')\n","    s10_deep_cnn_input = Input(shape=(64, 64, 3), name='stream_10_deep_cnn_input')\n","    s11_conv_ae_input = Input(shape=(16, 16, 8), name='stream_11_conv_autoencoder_input')\n","    s3_lstm_input = Input(shape=(ts_steps, ts_dim), name='stream_03_lstm_input')\n","    s4_gru_input = Input(shape=(ts_steps, ts_dim), name='stream_04_gru_input')\n","    s5_bidirectional_input = Input(shape=(ts_steps, ts_dim), name='stream_05_bidirectional_input')\n","    s6_timedistributed_input = Input(shape=(ts_steps, ts_dim), name='stream_06_timedistributed_input')\n","    s7_text_seq_input = Input(shape=(seq_len,), name='stream_07_text_seq_input')\n","    s8_transformer_input = Input(shape=(seq_len, seq_dim), name='stream_08_transformer_input')\n","    s2_structured_data_input = Input(shape=(data_size,), name='stream_02_structured_data_input')\n","    s12_fnn_input_100 = Input(shape=(100,), name='stream_12_fnn_input_100')\n","    s13_fnn_input_256 = Input(shape=(256,), name='stream_13_fnn_input_256')\n","    s14_vae_latent_input = Input(shape=(128,), name='stream_14_vae_latent_input')\n","    s15_rbm_feature_input = Input(shape=(64,), name='stream_15_rbm_feature_input')\n","    s16_graph_input_flat = Input(shape=(graph_dim * graph_dim,), name='stream_16_graph_input_flat')\n","    s17_attention_vector_input = Input(shape=(40,), name='stream_17_attention_vector_input')\n","    s18_custom_encoder_input = Input(shape=(80,), name='stream_18_custom_encoder_input')\n","    s19_residual_fwd_input = Input(shape=(512,), name='stream_19_residual_fwd_input')\n","    s20_residual_bwd_input = Input(shape=(512,), name='stream_20_residual_bwd_input')\n","    s21_residual_final_input = Input(shape=(512,), name='stream_21_residual_final_input')\n","    snn_vigilance_input = Input(shape=(1,), name='snn_vigilance_input')\n","    symbolic_bias_input = Input(shape=(1,), name='symbolic_bias_input')\n","    task_vector_input = Input(shape=(16,), name='task_vector_input')\n","\n","    retrieved_memory_and_causal = Input(shape=(FRONTAL_LOBE_UNITS + CAUSAL_STATE_DIM,), name='erm_retrieval_input')\n","    retrieved_state  = retrieved_memory_and_causal[:, :FRONTAL_LOBE_UNITS]\n","    retrieved_causal_context = retrieved_memory_and_causal[:, FRONTAL_LOBE_UNITS:]\n","\n","    input_list = [s1_image_input, s2_structured_data_input, s3_lstm_input, s4_gru_input, s5_bidirectional_input,\n","                 s6_timedistributed_input, s7_text_seq_input, s8_transformer_input, s9_small_cnn_input,\n","                 s10_deep_cnn_input, s11_conv_ae_input, s12_fnn_input_100, s13_fnn_input_256,\n","                 s14_vae_latent_input, s15_rbm_feature_input, s16_graph_input_flat, s17_attention_vector_input,\n","                 s18_custom_encoder_input, s19_residual_fwd_input, s20_residual_bwd_input, s21_residual_final_input]\n","    all_inputs = input_list + [snn_vigilance_input, symbolic_bias_input, task_vector_input, retrieved_memory_and_causal]"],"metadata":{"id":"vMyfeL9Df510"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 7: Multimodal Feature Extraction and RSA Integration\n","\n","This cell orchestrates the initial feature processing of the 21 data streams:\n","\n","* **Specialized Encoders:** Each stream is processed by an appropriate encoder ($\\text{Conv2D, LSTM, Embedding}$) before being funneled through a **Hybrid Synapse** (a $\\text{G-Plastic Dense}$ layer).\n","* **Relational Self-Attention (RSA) Application:** The raw features are projected into a common dimension ($\\text{PROJECTED\\_FEATURE\\_DIM}=512$) and then fed into the $\\text{RSA}$ layer, which outputs **attentional weights** used to scale the features.\n","* **Ventral/Dorsal Split:** The attended features are conceptually split into **Ventral** (what/object recognition) and **Dorsal** (where/action-oriented) streams for parallel processing, a key neuro-architectural feature."],"metadata":{"id":"g5JG7XGDgSKY"}},{"cell_type":"code","source":["# Cell 7 â€” Feature extraction and RSA projections\n","    # Helper\n","def extract_and_hybrid(input_tensor, units, name):\n","    return GPlasticDense(units, activation='tanh', name=f'hybrid_synapse_gplastic_{name}')(input_tensor)\n","\n","# Feature extraction\n","x = GPlasticConv2D(128, 3, activation='relu', padding='same')(s1_image_input)\n","f1 = extract_and_hybrid(Flatten()(x), 512, 'image')\n","s7_embedded = Embedding(input_dim=VOCAB_SIZE, output_dim=128, input_length=SEQ_LEN)(s7_text_seq_input)\n","f7 = extract_and_hybrid(GlobalMaxPooling1D()(s7_embedded), 256, 'text')\n","f3 = extract_and_hybrid(LSTM(256)(s3_lstm_input), 512, 'lstm')\n","f4 = extract_and_hybrid(GRU(256)(s4_gru_input), 512, 'gru')\n","f5 = extract_and_hybrid(Bidirectional(LSTM(256))(s5_bidirectional_input), 512, 'bidir')\n","s6_td_output = TimeDistributed(GPlasticDense(128, activation='relu'))(s6_timedistributed_input)\n","f6 = extract_and_hybrid(GlobalMaxPooling1D()(s6_td_output), 256, 'timedist')\n","f2 = extract_and_hybrid(s2_structured_data_input, 256, 'structured')\n","f8 = extract_and_hybrid(Flatten()(s8_transformer_input), 512, 'transformer')\n","f9_conv = GPlasticConv2D(64, 3, activation='relu')(s9_small_cnn_input)\n","f9 = extract_and_hybrid(Flatten()(f9_conv), 256, 'small_cnn')\n","f10_conv = GPlasticConv2D(128, 3, activation='relu')(s10_deep_cnn_input)\n","f10 = extract_and_hybrid(Flatten()(f10_conv), 512, 'deep_cnn')\n","f11_conv = GPlasticConv2D(64, 3, activation='relu')(s11_conv_ae_input)\n","f11 = extract_and_hybrid(Flatten()(f11_conv), 256, 'conv_ae')\n","f12 = extract_and_hybrid(s12_fnn_input_100, 256, 'fnn_100')\n","f13 = extract_and_hybrid(s13_fnn_input_256, 512, 'fnn_256')\n","f14 = extract_and_hybrid(s14_vae_latent_input, 512, 'vae_latent')\n","f15 = extract_and_hybrid(s15_rbm_feature_input, 256, 'rbm_feature')\n","f16 = extract_and_hybrid(s16_graph_input_flat, 512, 'graph_flat')\n","f17 = extract_and_hybrid(s17_attention_vector_input, 256, 'attention_vec')\n","f18 = extract_and_hybrid(s18_custom_encoder_input, 512, 'custom_encoder')\n","f19 = extract_and_hybrid(s19_residual_fwd_input, 512, 'residual_fwd')\n","f20 = extract_and_hybrid(s20_residual_bwd_input, 512, 'residual_bwd')\n","f21 = extract_and_hybrid(s21_residual_final_input, 512, 'residual_final')\n","\n","all_features_raw = [f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13, f14, f15, f16, f17, f18, f19, f20, f21]\n","\n","# RSA projections\n","PROJECTED_FEATURE_DIM = 512\n","projected_features = [GPlasticDense(PROJECTED_FEATURE_DIM, activation='relu', name=f'rsa_proj_gplastic_{i}')(f) for i, f in enumerate(all_features_raw)]\n","\n","rsa_features, rsa_weights, rsa_scores = RelationalSelfAttention(num_features=21, feature_dim=PROJECTED_FEATURE_DIM, name='relational_self_attention_unit')(projected_features)\n","\n","ventral_indices = [0, 6, 7, 8, 9, 10, 1, 11, 12, 13, 14, 16]\n","dorsal_indices = [2, 3, 4, 5, 15, 17, 18, 19, 20]\n","\n","rsa_ventral = [rsa_features[i] for i in ventral_indices]\n","rsa_dorsal = [rsa_features[i] for i in dorsal_indices]"],"metadata":{"id":"Mvs_F9dqg-Zh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 8: Core Fusion, GRU Recurrence, and HLS Injection\n","\n","This cell marks the transition from multimodal perception to **cognitive working memory**:\n","\n","1.  **Ventral/Dorsal Fusion:** The separate ventral and dorsal streams are concatenated and projected into the $\\text{FRONTAL\\_LOBE\\_UNITS}$ space.\n","2.  **ERM Fusion and GRU Recurrence:** The fused features are concatenated with the **Retrieved State** from $\\text{ERM}$ and passed into the $\\text{GPlasticGRU}$. This forms the **Current Working Memory State** (the core recurrent state).\n","3.  **HLS Injection:** The current working memory state is then immediately used to update the $\\text{Hyper-Latent State}$ via the $\\text{HLS\\_Processor}$."],"metadata":{"id":"udi4DmJVhdWT"}},{"cell_type":"code","source":["# Cell 8 â€” Fusion, GRU recurrence, HLS injection\n","ventral_features = Concatenate(name='ventral_path_fusion_rsa')(rsa_ventral)\n","ventral_features = GPlasticDense(FRONTAL_LOBE_UNITS, name='ventral_synapse_gplastic')(ventral_features)\n","\n","dorsal_features = Concatenate(name='dorsal_path_fusion_rsa')(rsa_dorsal)\n","dorsal_features = GPlasticDense(FRONTAL_LOBE_UNITS, name='dorsal_synapse_gplastic')(dorsal_features)\n","\n","fusion_features = Concatenate(name='core_fusion')([ventral_features, dorsal_features])\n","fusion_features = GPlasticDense(FRONTAL_LOBE_UNITS, name='core_pfc_input_synapse')(fusion_features)\n","fusion_features = BatchNormalization(name='pfc_input_bn')(fusion_features)\n","\n","fused_with_memory = Concatenate(name='fusion_with_erm')([fusion_features, retrieved_state])\n","\n","# HTSP placeholders (kept as Inputs so model signature matches your design)\n","htsp_fast_state = Input(shape=(FRONTAL_LOBE_UNITS,), name='htsp_fast_state')\n","htsp_slow_state_h = Input(shape=(FRONTAL_LOBE_UNITS,), name='htsp_slow_state_h')\n","htsp_slow_state_c = Input(shape=(FRONTAL_LOBE_UNITS,), name='htsp_slow_state_c')\n","\n","# GRU recurrence (plastic)\n","plastic_gru_output, current_working_memory_state = GPlasticGRU(FRONTAL_LOBE_UNITS, name='erm_gplastic_gru')(tf.expand_dims(fused_with_memory, axis=1))\n","\n","# HLS injection\n","hls_vector_raw = HLS_Processor(name='hls_processor')(current_working_memory_state)\n","hls_decoded = HLS_Decoder(name='hls_decoder')(hls_vector_raw)"],"metadata":{"id":"Sn6MYWOEhlMf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 9: The Final Executive and Predictive Heads\n","\n","This is the main orchestration cell where all executive functions are executed and the final outputs are generated:\n","\n","* **Executive Flow:** The working memory state passes through the $\\text{MLC, BG Selector, AKL, and CGW}$ to generate the highly-filtered $\\text{PFC Gated Output}$.\n","* **Predictive Working Memory (PWM):** The $\\text{PFC}$ output drives the main **predictive heads**: predicting the **next internal state**, the **next reward**, and the **next causal state** ($\\text{CIM}$). These predictions drive the primary self-supervised learning signal.\n","* **Model Assembly:** The `tcs_net_core` model is formally compiled, mapping all 25 inputs to the 10 required outputs (including all control/meta-learning vectors)."],"metadata":{"id":"8PtRQC3th1zv"}},{"cell_type":"code","source":["# --- Cell 9 â€” MCC, BG, CGW, PFC gating, predictions ---\n","\n","# Meta-Cognitive Control (MCC)\n","mcc_attention_budget = GPlasticDense(1, activation='sigmoid', name='mcc_attention_budget_gplastic')(current_working_memory_state)\n","mcc_confidence = GPlasticDense(1, activation='sigmoid', name='mcc_confidence_gplastic')(current_working_memory_state)\n","\n","# Meta-Learning Control (MLC)\n","mlc_output = MetaLearningControl(name='meta_learning_control_head')(current_working_memory_state)\n","mlc_plasticity_rate = mlc_output[:, 0:1]\n","\n","# Basal Ganglia (BG) and Axiomatic Knowledge Integration\n","bg_context_mask = BasalGangliaSelectionLayer(NUM_PFC_CONTEXTS, name='basal_ganglia_selector')(\n","    current_working_memory_state, task_vector_input\n",")\n","axiomatic_knowledge_vector = AxiomaticKnowledgeLayer(name='axiomatic_knowledge_layer')(bg_context_mask)\n","\n","# Conscious Global Workspace (CGW)\n","scaled_symbolic_bias = Multiply()([symbolic_bias_input, mcc_attention_budget])\n","scaled_vigilance = Multiply()([snn_vigilance_input, mcc_attention_budget])\n","\n","cgw_output = CGWAttentionLayer(name='conscious_global_workspace')(\n","    plastic_gru_output,\n","    scaled_symbolic_bias,\n","    scaled_vigilance,\n","    mcc_confidence,\n","    hls_decoded,\n","    axiomatic_knowledge_vector\n",")\n","\n","# Prefrontal Cortex (PFC) Executive Gating\n","pfc_gated_output = MultiContextExecutiveGating(\n","    FRONTAL_LOBE_UNITS, NUM_PFC_CONTEXTS, name='executive_gating_pfc_output'\n",")(cgw_output, bg_context_mask)\n","\n","# PWM Heads (Predictive Working Memory Outputs)\n","PWM_STATE_DIM = FRONTAL_LOBE_UNITS * 2 + CAUSAL_STATE_DIM\n","\n","predicted_next_state = GPlasticDense(\n","    PWM_STATE_DIM, activation='sigmoid', name='pwm_next_state_prediction_gplastic'\n",")(pfc_gated_output)\n","\n","predicted_next_reward = GPlasticDense(\n","    1, activation='tanh', name='pwm_next_reward_prediction_scalar_gplastic'\n",")(pfc_gated_output)\n","\n","# Causal Inference Module\n","predicted_causal_state = CausalInferenceModule(name='causal_inference_module')(\n","    pfc_gated_output, retrieved_causal_context\n",")\n","\n","# Final Outputs\n","final_classification_output = GPlasticDense(\n","    NUM_CLASSES, activation='softmax', name='classification_output_gplastic'\n",")(pfc_gated_output)\n","\n","final_confidence_output = mcc_confidence\n","\n","# --- Assemble Final Core Model ---\n","tcs_net_core = Model(\n","    inputs=all_inputs,\n","    outputs=[\n","        final_classification_output,\n","        predicted_next_state,\n","        predicted_next_reward,\n","        bg_context_mask,\n","        final_confidence_output,\n","        rsa_weights,\n","        predicted_causal_state,\n","        hls_vector_raw,\n","        mlc_plasticity_rate,\n","        axiomatic_knowledge_vector,\n","    ],\n","    name='Temporal_Causal_Synthesis_Network_Core'\n",")"],"metadata":{"id":"5uvtoT9IiBe3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["---\n","\n","## Cell 10: The TCS-25 Learner, Loss Functions, and Training Driver\n","\n","The final cell defines the overarching $\\text{TCS\\_GeneralIntelligence}$ model, the $\\text{Learner}$:\n","\n","1.  **Custom `train_step`:** The heart of the architecture is the custom $\\text{train\\_step}$ method. This is where the $\\text{G-Plasticity}$ updates are calculated and applied directly to the gradients, and the $\\text{MLC}$ rate, $\\text{Surprisal}$, and $\\text{Causal}$ signals are injected.\n","2.  **Self-Supervised Temporal Contrastive Loss ($\\text{L}_{\\text{SSTC}}$):** A critical loss function that ensures the predicted causal state and axiomatic knowledge are temporally consistent with the next true state, forcing the model to learn continuity.\n","3.  **Execution Driver:** The final script instantiates the model, generates **dummy data** (matching the 25 required inputs and 7 targets), compiles the custom metrics (including $\\text{Surprisal}$ and $\\text{Causal}$ magnitude), and executes a small training and inference demo."],"metadata":{"id":"64O69ROWiRqN"}},{"cell_type":"code","source":["# Cell 10 â€” Learner, data generator, training driver, inference\n","class TCS_GeneralIntelligence(Model):\n","    \"\"\"TCS-25: Learner with SSTC and plasticity handling.\"\"\"\n","    def __init__(self, tcs_net_core_model, snn_neuron, rule_reasoner, erm_buffer):\n","        super().__init__()\n","        self.tcs_net_core = tcs_net_core_model\n","        self.snn = snn_neuron\n","        self.rule_reasoner = rule_reasoner\n","        self.erm_buffer = erm_buffer\n","        self.sru = GPlasticDense(1, activation='sigmoid', name='sru_dopamine_gate')\n","\n","        self.classification_loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n","        self.state_prediction_loss_fn = tf.keras.losses.MeanSquaredError(name='state_prediction_mse_loss')\n","        self.reward_prediction_loss_fn = tf.keras.losses.MeanSquaredError(name='reward_prediction_mse_loss')\n","        self.confidence_loss_fn = tf.keras.losses.MeanSquaredError(name='confidence_mse_loss')\n","        self.causal_loss_fn = tf.keras.losses.MeanSquaredError(name='causal_mse_loss')\n","        self.hls_contrastive_loss_fn = tf.keras.losses.CosineSimilarity(axis=-1, name='hls_contrastive_loss')\n","        self.mlc_reg_loss_fn = tf.keras.losses.MeanSquaredError(name='mlc_reg_loss')\n","\n","        self.temporal_causal_contrastive_loss = tf.keras.losses.CosineSimilarity(axis=-1, name='sstc_loss')\n","\n","        self.plasticity_targets = []\n","        for layer in tcs_net_core_model.layers:\n","            if isinstance(layer, GPlasticityMixin):\n","                self.plasticity_targets.append(layer)\n","            if hasattr(layer, 'proj_input') and isinstance(layer.proj_input, GPlasticDense):\n","                self.plasticity_targets.append(layer.proj_input)\n","            if isinstance(layer, HLS_Processor) and isinstance(layer.latent_dense, GPlasticDense):\n","                self.plasticity_targets.append(layer.latent_dense)\n","            if isinstance(layer, Dense) and hasattr(layer, 'w_old'):\n","                self.plasticity_targets.append(layer)\n","\n","    def compile(self, optimizer, loss, metrics=None):\n","        if metrics is None: metrics = []\n","        metrics.extend([\n","            tf.keras.metrics.Mean(name='classification_loss'),\n","            tf.keras.metrics.Mean(name='state_prediction_loss'),\n","            tf.keras.metrics.Mean(name='causal_prediction_loss'),\n","            tf.keras.metrics.Mean(name='hls_contrastive_loss'),\n","            tf.keras.metrics.Mean(name='sstc_loss_mean'),\n","            tf.keras.metrics.Mean(name='mlc_rate_mean'),\n","            tf.keras.metrics.Mean(name='surprisal_update_mag'),\n","            tf.keras.metrics.Mean(name='causal_update_mag')\n","        ])\n","        super().compile(optimizer=optimizer, loss=loss, metrics=metrics)\n","\n","    @tf.function\n","    def train_step(self, data):\n","        (x_data, y_targets) = data\n","        x_inputs = x_data[:21]\n","        x_snn_vigilance_raw = x_data[21]\n","        x_symbolic_bias_raw = x_data[22]\n","        x_task_vector = x_data[23]\n","\n","        y_true_classification = y_targets[0]\n","        y_true_next_state = y_targets[1]\n","        y_true_next_reward = y_targets[2]\n","        y_true_confidence = y_targets[3]\n","        y_true_causal_state = y_targets[4]\n","        y_true_next_hls = y_targets[5]\n","        y_true_temporal_causal = y_targets[6]\n","\n","        query_vector = x_inputs[18][0:1]\n","        retrieved_mem_causal = self.erm_buffer.retrieve_context(query_vector)\n","        x_retrieved_mem_causal = tf.tile(retrieved_mem_causal, [tf.shape(x_inputs[0])[0], 1])\n","\n","        total_surprisal_mag = tf.constant(0.0)\n","        total_causal_mag = tf.constant(0.0)\n","\n","        with tf.GradientTape() as tape:\n","            core_inputs = x_inputs + [x_snn_vigilance_raw, x_symbolic_bias_raw, x_task_vector, x_retrieved_mem_causal]\n","            y_pred_classification, y_pred_state, y_pred_reward, context_mask, y_pred_confidence, rsa_weights, y_pred_causal, y_pred_hls, mlc_plasticity_rate, axiomatic_vector = self.tcs_net_core(core_inputs, training=True)\n","\n","            state_prediction_loss = self.state_prediction_loss_fn(y_true_next_state, y_pred_state)\n","            reward_prediction_loss = self.reward_prediction_loss_fn(y_true_next_reward, y_pred_reward)\n","            causal_prediction_loss = self.causal_loss_fn(y_true_causal_state, y_pred_causal)\n","            classification_loss = self.classification_loss_fn(y_true_classification, y_pred_classification)\n","            confidence_loss = self.confidence_loss_fn(y_true_confidence, y_pred_confidence)\n","            rsa_sparsity_loss = tf.reduce_mean(tf.norm(rsa_weights, ord=1, axis=-1)) * 0.0005\n","\n","            hls_contrastive_loss = (1 + self.hls_contrastive_loss_fn(y_true_next_hls, y_pred_hls)) * 0.005\n","            mlc_reg_loss = tf.reduce_mean(mlc_plasticity_rate) * 0.0001\n","            sstc_loss = (1 + self.temporal_causal_contrastive_loss(y_true_temporal_causal, Concatenate()([y_pred_causal, axiomatic_vector]))) * 0.01\n","\n","            total_loss = classification_loss \\\n","                       + (LOSS_WEIGHT_SSTC * state_prediction_loss) \\\n","                       + (LOSS_WEIGHT_SSTC * reward_prediction_loss) \\\n","                       + (LOSS_WEIGHT_SSTC * causal_prediction_loss) \\\n","                       + confidence_loss \\\n","                       + rsa_sparsity_loss \\\n","                       + hls_contrastive_loss \\\n","                       + mlc_reg_loss \\\n","                       + sstc_loss\n","\n","        mean_pred_error = tf.expand_dims(tf.reduce_mean(state_prediction_loss + reward_prediction_loss), axis=-1)\n","        sru_input_enhanced = Concatenate()([x_snn_vigilance_raw[0:1], mean_pred_error, y_pred_confidence[0:1]])\n","        global_surprisal_rate = self.sru(sru_input_enhanced)\n","        global_causal_rate = tf.expand_dims(tf.reduce_mean(causal_prediction_loss + sstc_loss), axis=-1)\n","\n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(total_loss, trainable_vars)\n","\n","        for layer in self.plasticity_targets:\n","            # set neuromodulatory signals (tensors)\n","            layer.dynamic_plasticity_strength = mlc_plasticity_rate\n","            layer.surprisal_signal = global_surprisal_rate\n","            layer.causal_signal = global_causal_rate\n","\n","            target_var = None\n","            if hasattr(layer, 'kernel') and layer.kernel in trainable_vars:\n","                target_var = layer.kernel\n","            elif hasattr(layer, 'w') and layer.w in trainable_vars:\n","                target_var = layer.w\n","\n","            if target_var is not None:\n","                delta_p, mag_p = layer.calculate_plasticity_change()\n","                try:\n","                    var_index = trainable_vars.index(target_var)\n","                    if gradients[var_index] is not None:\n","                        try:\n","                            gradients[var_index] = gradients[var_index] - delta_p\n","                        except Exception:\n","                            gradients[var_index] = gradients[var_index] - tf.cast(delta_p, gradients[var_index].dtype)\n","                except ValueError:\n","                    pass\n","\n","                total_surprisal_mag += mag_p * global_surprisal_rate[0,0]\n","                total_causal_mag += mag_p * global_causal_rate[0,0]\n","\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        self.compiled_metrics.update_state(y_true_classification, y_pred_classification)\n","\n","        state_to_store = Concatenate(axis=-1)([y_pred_state, y_pred_reward])\n","        self.erm_buffer.store(state_to_store, context_mask, y_pred_causal)\n","\n","        return {m.name: m.result() for m in self.metrics}\n","\n","# Data generator (same as original)\n","def generate_dummy_data_tcs_net(n_samples, num_classes):\n","    ts_steps, ts_dim, seq_len, seq_dim, graph_dim = TS_STEPS, TS_DIM, SEQ_LEN, SEQ_DIM, GRAPH_DIM\n","    X_inputs_data = [\n","        np.random.rand(n_samples, *IMAGE_SHAPE).astype(np.float32),\n","        np.random.rand(n_samples, DATA_INPUT_SIZE).astype(np.float32),\n","        np.random.rand(n_samples, ts_steps, ts_dim).astype(np.float32),\n","        np.random.rand(n_samples, ts_steps, ts_dim).astype(np.float32),\n","        np.random.rand(n_samples, ts_steps, ts_dim).astype(np.float32),\n","        np.random.rand(n_samples, ts_steps, ts_dim).astype(np.float32),\n","        tf.constant(np.random.randint(0, VOCAB_SIZE, size=(n_samples, seq_len))),\n","        np.random.rand(n_samples, seq_len, seq_dim).astype(np.float32),\n","        np.random.rand(n_samples, 32, 32, 1).astype(np.float32),\n","        np.random.rand(n_samples, 64, 64, 3).astype(np.float32),\n","        np.random.rand(n_samples, 16, 16, 8).astype(np.float32),\n","        np.random.rand(n_samples, 100).astype(np.float32),\n","        np.random.rand(n_samples, 256).astype(np.float32),\n","        np.random.rand(n_samples, 128).astype(np.float32),\n","        np.random.rand(n_samples, 64).astype(np.float32),\n","        np.random.rand(n_samples, graph_dim * graph_dim).astype(np.float32),\n","        np.random.rand(n_samples, 40).astype(np.float32),\n","        np.random.rand(n_samples, 80).astype(np.float32),\n","        np.random.rand(n_samples, 512).astype(np.float32),\n","        np.random.rand(n_samples, 512).astype(np.float32),\n","        np.random.rand(n_samples, 512).astype(np.float32),\n","    ]\n","    X_controls = [\n","        np.random.rand(n_samples, 1).astype(np.float32),\n","        np.random.rand(n_samples, 1).astype(np.float32),\n","        np.random.rand(n_samples, 16).astype(np.float32)\n","    ]\n","    X_inputs_all = X_inputs_data + X_controls\n","    Y_classification = tf.one_hot(np.random.randint(0, num_classes, n_samples), depth=num_classes)\n","    PWM_STATE_DIM = FRONTAL_LOBE_UNITS * 2 + CAUSAL_STATE_DIM\n","    Y_true_next_state = np.random.rand(n_samples, PWM_STATE_DIM).astype(np.float32)\n","    Y_true_next_reward = np.random.rand(n_samples, 1).astype(np.float32)\n","    Y_true_confidence = 1.0 - np.random.rand(n_samples, 1).astype(np.float32) * 0.5\n","    Y_true_causal_state = np.random.rand(n_samples, CAUSAL_STATE_DIM).astype(np.float32)\n","    Y_true_next_hls = np.random.rand(n_samples, HYPER_LATENT_DIM).astype(np.float32)\n","    SSTC_TARGET_DIM = CAUSAL_STATE_DIM + AXIOMATIC_DIM\n","    Y_true_temporal_causal = np.random.rand(n_samples, SSTC_TARGET_DIM).astype(np.float32)\n","    Y_targets = [Y_classification, Y_true_next_state, Y_true_next_reward, Y_true_confidence, Y_true_causal_state, Y_true_next_hls, Y_true_temporal_causal]\n","    return X_inputs_all, Y_targets\n","\n","# Execution driver (small demo; may be heavy in Colab)\n","N_SAMPLES = 1024\n","EPOCHS = 3\n","print(\"\\nðŸŒŒ --- ASSEMBLING TEMPORAL CAUSAL SYNTHESIS NETWORK (TCS-25) --- ðŸŒŒ\")\n","\n","try:\n","    tcs_net_core = build_tcs_net_core_model(IMAGE_SHAPE, DATA_INPUT_SIZE, TS_STEPS, TS_DIM, SEQ_LEN, SEQ_DIM, GRAPH_DIM, NUM_CLASSES)\n","    class LIFNeuron: pass\n","    class RuleBasedReasoner: pass\n","    snn_neuron_instance = LIFNeuron()\n","    rule_reasoner_instance = RuleBasedReasoner()\n","    erm_buffer_instance = EpisodicRelationalMemory()\n","\n","    tcs_net_model = TCS_GeneralIntelligence(tcs_net_core, snn_neuron_instance, rule_reasoner_instance, erm_buffer_instance)\n","\n","    tcs_net_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n","\n","    X_inputs_all, Y_targets = generate_dummy_data_tcs_net(N_SAMPLES, NUM_CLASSES)\n","\n","    print(f\"\\n--- Starting TCS-25 Training ({N_SAMPLES} Samples, {EPOCHS} Epochs) ---\")\n","    history = tcs_net_model.fit(X_inputs_all, Y_targets, epochs=EPOCHS, batch_size=TRAINING_BATCH_SIZE, verbose=1)\n","    print(\"\\nâœ… Training Complete. TCS-25 is functional and hyper-plastic.\")\n","except NameError as e:\n","    print(f\"ðŸš¨ ERROR: A required constant or class is missing. Error: {e}\")\n","except Exception as e:\n","    print(f\"ðŸš¨ ERROR during Training: {e}\")\n","    print(traceback.format_exc())\n","\n","# Minimal inference demo\n","print(\"\\n--- Executing Minimal TCS-25 Inference Cycle ---\")\n","try:\n","    X_test_all, _ = generate_dummy_data_tcs_net(1, NUM_CLASSES)\n","    query_vector = X_test_all[18][0:1]\n","    X_test_erm_retrieval = erm_buffer_instance.retrieve_context(query_vector)\n","    X_test_final = X_test_all + [X_test_erm_retrieval.numpy()]\n","    results = tcs_net_core.predict(X_test_final, verbose=0)\n","    final_output, pred_state, pred_reward, context_mask, pred_confidence, rsa_weights, pred_causal, pred_hls, mlc_rate, axiomatic_vector = results\n","\n","    try:\n","        surprisal_metric = tcs_net_model.get_metric('surprisal_update_mag')\n","        causal_metric = tcs_net_model.get_metric('causal_update_mag')\n","        sstc_metric = tcs_net_model.get_metric('sstc_loss_mean')\n","    except Exception:\n","        surprisal_metric = causal_metric = sstc_metric = None\n","\n","    surprisal_mag = surprisal_metric.result().numpy() if surprisal_metric is not None else 0.0\n","    causal_mag = causal_metric.result().numpy() if causal_metric is not None else 0.0\n","    sstc_loss = sstc_metric.result().numpy() if sstc_metric is not None else 0.0\n","\n","    attended_indices = np.argsort(rsa_weights[0])[-3:][::-1]\n","\n","    print(\"\\n====================================================\")\n","    print(\"  TEMPORAL CAUSAL SYNTHESIS NETWORK (TCS-25) RESULTS \")\n","    print(\"====================================================\")\n","    print(f\"   -> Raw Predicted Class: {np.argmax(final_output[0])}   (Prob: {np.max(final_output[0]):.4f})\")\n","    print(f\"   -> Predicted Next Reward (PWM): {pred_reward[0,0]:.4f}\")\n","    print(f\"   -> Inferred Winning Context (BG): Context {np.argmax(context_mask[0])}\")\n","    print(f\"   -> Predicted System Confidence (MCC Output): {pred_confidence[0,0]:.4f}\")\n","    print(f\"   -> Predicted Causal State (CIM Output): Mean: {np.mean(pred_causal[0]):.4f}\")\n","    print(f\"   -> Axiomatic Knowledge Vector (AKE): L2 Norm: {np.linalg.norm(axiomatic_vector[0]):.4f}\")\n","    print(f\"   -> Dynamic Plasticity Rate (MLC Output): {mlc_rate[0,0]:.6f}\")\n","    print(f\"   -> HLS L1 Norm (Sparsity Check): {np.linalg.norm(pred_hls[0], ord=1):.4f}\")\n","    print(f\"   -> SSTC Loss (Temporal Consistency Check): {sstc_loss:.6f}\")\n","    print(f\"   -> G-Plasticity Surprisal Update Magnitude (Avg.): {surprisal_mag:.4f}\")\n","    print(f\"   -> G-Plasticity Causal Update Magnitude (Avg.): {causal_mag:.4f}\")\n","    print(f\"   -> Top 3 Attended Feature Streams (RSA): Index {attended_indices[0]} ({rsa_weights[0, attended_indices[0]]:.4f}), Index {attended_indices[1]} ({rsa_weights[0, attended_indices[1]]:.4f})\")\n","    print(\"====================================================\")\n","except Exception as e:\n","    print(f\"âŒ ERROR during TCS-25 Inference Demo: {e}\")\n","    print(traceback.format_exc())"],"metadata":{"id":"3K3-r4A8iklb"},"execution_count":null,"outputs":[]}]}